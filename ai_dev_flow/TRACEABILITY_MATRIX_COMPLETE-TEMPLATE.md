---
title: "Traceability Matrix Complete Template"
tags:
  - traceability-template
  - shared-architecture
custom_fields:
  document_type: template
  priority: shared
  development_status: active
---

# Complete Traceability Matrix: End-to-End SDD Workflow

## Document Control

| Item | Details |
|------|---------|
| Document ID | TRACEABILITY_MATRIX_COMPLETE |
| Title | Complete End-to-End Traceability Matrix |
| Status | Active |
| Version | 1.0.0 |
| Date Created | YYYY-MM-DD |
| Author | [Team Name] |
| Purpose | Track complete traceability chain: Strategy â†’ BRD â†’ PRD â†’ EARS â†’ BDD â†’ ADR â†’ SYS â†’ REQ â†’ CTR â†’ SPEC â†’ TASKS â†’ Code â†’ Production |

---

Note: Some examples in this document show a portable `docs/` root. In this repository, artifact folders live at the ai_dev_flow root without the `docs/` prefix; see README â†’ â€œUsing This Repoâ€ for path mapping.

**âš ï¸ TAG-BASED AUTO-GENERATION AVAILABLE**

This traceability matrix can be automatically generated by scanning code files for @brd:, @sys:, @spec:, @test: tags.

**Recommended Approach:** Use tag-based auto-discovery instead of manual maintenance.

**Generate automatically using:**
```bash
# NOTE: In this ai_dev_flow repo, drop any `docs/` prefix shown in generic examples.
# Extract tags from all files
python scripts/extract_tags.py --source src/ docs/ tests/ --output docs/generated/tags.json

# Validate tags against documents
python scripts/validate_tags_against_docs.py --tags docs/generated/tags.json --strict

# Generate complete traceability matrices
python scripts/generate_traceability_matrix.py --tags docs/generated/tags.json --output docs/generated/matrices/
```

**Benefits:**
- âœ… Single source of truth: Tags embedded in code
- âœ… Always up-to-date: Generated from current codebase
- âœ… No manual sync: Automated validation prevents drift
- âœ… Coverage metrics: Automatically calculated

**Tag Format:** `@brd: BRD.01.01.30, BRD.01.01.06`

See: [TRACEABILITY.md](./TRACEABILITY.md#tag-based-auto-discovery-alternative) for complete tag-based workflow.

---

## 1. Overview

### 1.1 Complete SDD Workflow

This matrix tracks the complete 15-layer AI-Driven Specification-Driven Development workflow (Layer 0: Strategy through Layer 14: Validation):

**Layers 1-3 - Business**: BRD (L1) â†’ PRD (L2) â†’ EARS (L3)
**Layer 4 - Testing**: BDD (acceptance criteria)
**Layers 5-6 - Architecture**: ADR (L5) â†’ SYS (L6) - technical decisions
**Layer 7 - Requirements**: REQ (atomic requirements)
**Layer 8 - Interface**: CTR (API contracts) - optional
**Layer 9 - Technical Specifications**: SPEC (YAML blueprints)
**Layer 10 - Code Generation**: TASKS (implementation steps with execution commands)
**Layer 11 - Code**: Source code implementation
**Layer 12 - Tests**: Test execution and verification
**Layer 14: Validation â†’ Review â†’ Production

### 1.2 Coverage Summary

**Note:** Coverage metrics can be automatically calculated from tag extraction:
```bash
python scripts/generate_traceability_matrix.py --auto --report
```

| Document Type | Total Created | Coverage % | Status |
|---------------|---------------|------------|--------|
| **Business Layer** | | | |
| BRD | [X]/[Y] | XX% | [Status] |
| PRD | [X]/[Y] | XX% | [Status] |
| EARS | [X]/[Y] | XX% | [Status] |
| **Testing Layer** | | | |
| BDD | [X]/[Y] | XX% | [Status] |
| **Architecture Layer** | | | |
| ADR | [X]/[Y] | XX% | [Status] |
| SYS | [X]/[Y] | XX% | [Status] |
| **Requirements Layer** | | | |
| REQ | [X]/[Y] | XX% | [Status] |
| **Interface Layer** | | | |
| CTR | [X]/[Y] | XX% | [Status] |
| **Technical Specs (SPEC) (Layer 9)** | | | |
| SPEC | [X]/[Y] | XX% | [Status] |
| **Code Generation Layer (Layer 10)** | | | |
| TASKS | [X]/[Y] | XX% | [Status] |
| **Execution Layer** | | | |
| Code Files | [X]/[Y] | XX% | [Status] |
| Test Files | [X]/[Y] | XX% | [Status] |
| **Total** | **[X]/[Y]** | **XX%** | **[Status]** |

### 1.3 Workflow Completeness Metrics

| Workflow Stage | Expected Documents | Actual Documents | Gap | Status |
|----------------|-------------------|------------------|-----|--------|
| Strategy â†’ Business | [X] 01_BRD/02_PRD/EARS | [Y] | [Z] | [Status] |
| Business â†’ Testing | [X] BDD | [Y] | [Z] | [Status] |
| Business â†’ Architecture | [X] 05_ADR/SYS | [Y] | [Z] | [Status] |
| Architecture â†’ Requirements | [X] REQ | [Y] | [Z] | [Status] |
| Requirements â†’ Contracts | [X] CTR | [Y] | [Z] | [Status] |
| Contracts â†’ Implementation | [X] 09_SPEC/TASKS | [Y] | [Z] | [Status] |
| Implementation â†’ Code | [X] Code/Tests | [Y] | [Z] | [Status] |

---

## 2. Cumulative Tagging Hierarchy

### 2.1 Overview

AI Dev Flow implements **cumulative tagging** where each artifact type must include traceability tags from ALL upstream artifact types. This creates complete end-to-end traceability chains from business strategy through production deployment.

**Key Principle**: Each layer inherits ALL tags from upstream layers and adds its own.

### Traceability Rules (REQUIRED vs OPTIONAL)

| Document Type | Upstream Traceability | Downstream Traceability |
|---------------|----------------------|------------------------|
| **BRD** | OPTIONAL (to other BRDs) | OPTIONAL |
| **All Other Documents** | REQUIRED | OPTIONAL |

**Key Rules**:
- **Upstream REQUIRED** (except BRD): Document MUST reference its upstream sources
- **Downstream OPTIONAL**: Only link to documents that already exist
- **No-TBD Rule**: NEVER use placeholder IDs (TBD, XXX, NN) - leave empty or omit section

### 2.2 Tag Format

```markdown
@artifact-type: TYPE.NN.TT.SS (Unified Feature ID)
```

**Format Rules**:
- Prefix: `@` symbol
- Artifact Type: lowercase (brd, prd, ears, bdd, adr, sys, req, ctr, spec, tasks)
- Separator: colon `:` after artifact type
- Document ID: `TYPE-NN` format
- Requirement ID: specific requirement/section identifier
- Multiple Values: comma-separated `@brd: BRD.01.01.30, BRD.01.01.06`

### 2.3 Cumulative Tagging Table

| Layer | Artifact Type | Required Tags | Tag Count | Tracking Method | Notes |
|-------|---------------|---------------|-----------|-----------------|-------|
| 0 | **Strategy** | None | 0 | External | Business owner documents, no formal artifact |
| 1 | **BRD** | None | 0 | Formal Template (Markdown) | Top level, no upstream dependencies |
| 2 | **PRD** | `@brd` | 1 | Formal Template (Markdown) | References parent BRD |
| 3 | **EARS** | `@brd`, `@prd` | 2 | Formal Template (Markdown) | Engineering Requirements (Event-Action-Response-State) |
| 4 | **BDD** | `@brd`, `@prd`, `@ears` | 3+ | Formal Template + Gherkin Tags | Cumulative: BRD through EARS + standard BDD tags |
| 5 | **ADR** | `@brd`, `@prd`, `@ears`, `@bdd` | 4 | Formal Template (Markdown) | Cumulative: BRD through BDD |
| 6 | **SYS** | `@brd` through `@adr` | 5 | Formal Template (Markdown) | Cumulative: BRD through ADR |
| 7 | **REQ** | `@brd` through `@sys` | 6 | Formal Template (Markdown) | Cumulative: BRD through SYS |
| 8 | **CTR** | `@brd` through `@req` | 7 | Formal Template (Markdown + YAML) | Optional layer - include if exists |
| 9 | **SPEC** | `@brd` through `@req` + optional `@ctr` | 7-8 | Formal Template (YAML) | YAML cumulative_tags section |
| 10 | **TASKS** | `@brd` through `@spec` | 8-9 | Formal Template (Markdown) | Cumulative: BRD through SPEC |
| 11 | **Code** | `@brd` through `@tasks` | 9-10 | Code Docstrings (Python/JS/etc.) | Tags in module/class/function docstrings |
| 12 | **Tests** | `@brd` through code tags + `@code` | 10-11 | BDD + Docstrings | Test files reference code + all upstream |
| 13 | **Validation** | All upstream tags | 11-12 | Embedded + CI/CD | Deployment and validation artifacts |

### 2.4 Cumulative Tag Chain Examples

#### Example 1: SPEC Artifact (Layer 9)

```yaml
# SPEC-NN: request submission Service Specification

# ... spec content ...

cumulative_tags:
  brd: "BRD.09.01.15"
  prd: "PRD.16.01.03"
  ears: "EARS.12.24.02"
  bdd: "BDD.15.13.01"
  adr: "ADR-NN"
  sys: "SYS.12.25.01"
  req: "REQ.45.26.01"
  ctr: "CTR-NN"  # Optional - included if exists
```

**Tag Count**: 8 tags (7 required + 1 optional)

#### Example 2: Code Artifact (Layer 11)

```python
"""
request submission Service

Handles request submission with validation and execution.

## 3. Traceability Tags

@brd: BRD.09.01.15, BRD.09.01.06
@prd: PRD.16.01.03
@ears: EARS.12.24.02, EARS.12.24.01
@bdd: BDD.15.13.01, BDD.15.13.02
@adr: ADR-NN
@sys: SYS.12.25.01, SYS.12.25.02
@req: REQ.45.26.01, REQ.45.26.02
@ctr: CTR-NN
@spec: SPEC-NN
@tasks: TASKS.18.29.03, TASKS.18.29.07

@test-coverage: 95%
"""
```

**Tag Count**: 10 upstream tags (all required for Layer 11)

#### Example 3: Test Artifact (Layer 12)

```python
"""
Test suite for request submission Service

## 4. Traceability Tags

@brd: BRD.09.01.15, BRD.09.01.06
@prd: PRD.16.01.03
@ears: EARS.12.24.02, EARS.12.24.01
@bdd: BDD.15.13.01, BDD.15.13.02
@adr: ADR-NN
@sys: SYS.12.25.01, SYS.12.25.02
@req: REQ.45.26.01, REQ.45.26.02
@ctr: CTR-NN
@spec: SPEC-NN
@tasks: TASKS.18.29.03, TASKS.18.29.07
@code: src/execution/order_service.py:OrderService

@test-type: integration
@test-coverage: 100%
"""
```

**Tag Count**: 11 upstream tags (including code reference)

### 2.5 Validation Rules

#### Tag Completeness Rules

1. **Required Tags**: Each artifact MUST include ALL tags from upstream layers
2. **Optional Layers**: CTR (Layer 8) is optional - include only if it exists in chain
3. **No Skipping**: Cannot skip intermediate layers (e.g., cannot reference BRD and REQ without intermediate layers)
4. **Format Compliance**: All tags must follow `@type: DOC-ID:REQ-ID` format

#### Validation Queries

**Check for Missing Upstream Tags**:
```bash
# Validate that SPEC-NN has all required upstream tags
python scripts/validate_tags_against_docs.py \
  --artifact SPEC-NN \
  --expected-layers brd,prd,ears,bdd,adr,sys,req \
  --strict
```

**Check Tag Format Compliance**:
```bash
# Verify all tags in codebase follow correct format
python scripts/extract_tags.py \
  --source src/ docs/ tests/ \
  --validate-format \
  --strict
```

**Generate Missing Tag Report**:
```bash
# Find all artifacts with incomplete tag chains
python scripts/generate_traceability_matrix.py \
  --check-completeness \
  --report-gaps
```

### 2.6 Benefits of Cumulative Tagging

1. **Complete Traceability**: Every artifact links back to original business requirements
2. **Impact Analysis**: Quickly identify all affected artifacts when requirements change
3. **Automated Validation**: Scripts can verify tag completeness and format
4. **Gap Detection**: Missing tags indicate incomplete traceability chains
5. **Requirements Coverage**: Validate that all business requirements have implementations
6. **Audit Trail**: Full history from strategy through production deployment

### 2.7 Common Patterns

#### Pattern 1: Feature Development Chain

```
Strategy Document
  â†“ @brd
BRD-NN (Business Requirements)
  â†“ @brd, @prd
PRD-NN (Product Requirements)
  â†“ @brd, @prd, @ears
EARS-NN (Engineering Requirements)
  â†“ @brd, @prd, @ears, @bdd
BDD-NN (Test Scenarios)
  â†“ @brd through @bdd, @adr
ADR-NN (Architecture Decision)
  â†“ @brd through @adr, @sys
SYS-NN (System Requirements)
  â†“ @brd through @sys, @req
REQ-NN (Atomic Requirement)
  â†“ @brd through @req, @ctr
CTR-NN (API Contract)
  â†“ @brd through @ctr, @spec
SPEC-NN (Technical Specification)
  â†“ @brd through @spec, @tasks
TASKS-NN (Implementation Tasks)
  â†“ @brd through @tasks, @code
Code: src/execution/order_service.py
  â†“ @brd through @code, @test
Tests: tests/test_order_service.py
  â†“ All tags validated
Production Deployment
```

#### Pattern 2: Simplified Chain (No Optional Layers)

When CTR layer doesn't exist:

```
BRD-NN â†’ PRD-NN â†’ EARS-NN â†’ BDD-NN â†’ ADR-NN â†’ SYS-NN â†’ REQ-NN
  â†“
SPEC-NN (tags: @brd through @req = 7 tags)
  â†“
TASKS-NN (tags: @brd through @spec = 8 tags)
  â†“
Code (tags: @brd through @tasks = 9 tags)
```

---

## 3. Complete Workflow Traceability Map

### 3.1 Business Layer Traceability

| Strategy Source | BRD ID | PRD ID | EARS ID | BDD ID | Status |
|-----------------|--------|--------|---------|--------|--------|
| [Strategic Goal 1] | BRD-NN | PRD-NN | EARS-NN | BDD-NN | âœ… Complete |
| [Strategic Goal 2] | BRD-NN | PRD-NN | EARS-NN | BDD-NN | âœ… Complete |
| [Strategic Goal 3] | BRD-NN | PRD-NN | EARS-NN | BDD-NN | ðŸŸ¡ Partial |
| [Strategic Goal N] | ... | ... | ... | ... | ... |

### 3.2 Architecture Layer Traceability

| BRD ID | PRD ID | EARS ID | ADR ID | SYS ID | REQ IDs | Status |
|--------|--------|---------|--------|--------|---------|--------|
| BRD-NN | PRD-NN | EARS-NN | ADR-NN | SYS-NN | REQ-NN | âœ… Complete |
| BRD-NN | PRD-NN | EARS-NN | ADR-NN | SYS-NN | REQ-NN | âœ… Complete |
| BRD-NN | PRD-NN | EARS-NN | ADR-NN | SYS-NN | REQ-NN | ðŸŸ¡ Partial |
| ... | ... | ... | ... | ... | ... | ... |

### 3.3 Implementation and Code Generation Traceability

**Note:** This table can be auto-generated from @brd:, @req:, @spec:, @test: tags in code docstrings.

| REQ ID | CTR ID | SPEC ID | TASKS ID | Code Files | Tag Discovery | Tests | Status |
|--------|--------|---------|----------|------------|---------------|-------|--------|
| REQ-NN | CTR-NN | SPEC-NN | TASKS-NN | src/module.py | @req: REQ.NN.EE.SS | test_module.py | âœ… Complete |
| REQ-NN | N/A | SPEC-NN | TASKS-NN | src/service.py | N/A | test_service.py | âœ… Complete |
| REQ-NN | CTR-NN | SPEC-NN | TASKS-NN | src/api.py | N/A | test_api.py | ðŸŸ¡ In Progress |
| REQ-NN | N/A | SPEC-NN | â³ Pending | â³ Pending | â³ Pending | â³ Pending | â³ Not Started |
| ... | ... | ... | ... | ... | ... | ... | ... |

### 3.4 Validation Layer Traceability

| BDD ID | EARS ID | Code Files | Test Files | Test Results | Production Status | Status |
|--------|---------|------------|------------|--------------|-------------------|--------|
| BDD-NN | EARS-NN | src/module.py | test_module.py | âœ… Passed (100%) | âœ… Deployed v1.0 | Complete |
| BDD-NN | EARS-NN | src/service.py | test_service.py | âœ… Passed (95%) | âœ… Deployed v1.0 | Complete |
| BDD-NN | EARS-NN | src/api.py | test_api.py | ðŸŸ¡ Partial (80%) | ðŸŸ¡ Staging | Testing |
| BDD-NN | EARS-NN | â³ Pending | â³ Pending | â³ Not Tested | â³ Not Deployed | Not Started |
| ... | ... | ... | ... | ... | ... | ... |

---

## 3. End-to-End Traceability Examples

### 3.1 Example 1: Complete Feature Implementation Chain

```
Strategy: [Strategic Document section X.Y]
   â†“ drives
BRD-NN: service integration Business Requirements
   â†“ defines
PRD-NN: operation execution Product Requirements
   â†“ formalizes
EARS-NN: operation execution formal requirements (WHEN a user submits a request, THE system SHALL execute action WITHIN [time])
   â†“ validates
BDD-NN: operation execution acceptance tests (Gherkin scenarios)
   â†“ informs
ADR-NN: operation execution architecture decision (Event-driven architecture for operation processing)
   â†“ defines
SYS-NN: operation execution system requirements (Event bus, operation processing service)
   â†“ decomposes
REQ-NN: Submit constrained operation request (atomic requirement)
   â†“ specifies
CTR-NN: operation execution API contract (.md + .yaml)
   â†“ implements
SPEC-NN: request submission service specification (YAML blueprint)
   â†“ guides
TASKS-NN: request submission implementation tasks (15 step-by-step TODOs)
   â†“ generates
Code: src/execution/order_service.py (implements CTR-NN, 350 LOC)
   â†“ verifies
Tests: tests/test_order_service.py + contract tests (95% coverage)
   â†“ validates
BDD-NN: Acceptance tests pass (100% scenarios passing)
   â†“ deploys
Production: Deployed v1.2.0 (YYYY-MM-DD)
```

**Status**: âœ… Complete end-to-end traceability

### 3.2 Example 2: Partial Implementation Chain (Gap Identification)

```
Strategy: [Business Analysis Report section 4.3]
   â†“
BRD-NN: ML-Based Real-Time Sentiment Analysis
   â†“
PRD-NN: Real-time sentiment scoring for user-generated content
   â†“
EARS-NN: WHEN new input data arrives, THE system SHALL compute sentiment score WITHIN 500ms
   â†“
BDD-NN: Sentiment calculation test scenarios
   â†“
ADR-NN: ML model architecture for sentiment analysis
   â†“
SYS-NN: Sentiment service system requirements
   â†“
REQ-NN: Calculate sentiment score from input data
   â†“ [GAP: CTR missing]
âš ï¸ CTR-NN: No API contract defined for sentiment service
   â†“
SPEC-NN: Sentiment scoring service specification (YAML)
   â†“ [GAP: TASKS missing]
âš ï¸ TASKS-NN: No code generation plan created
   â†“ [GAP: Code missing]
âš ï¸ Code: Implementation not started
   â†“ [GAP: Tests missing]
âš ï¸ Tests: No tests created
   â†“ [GAP: Validation missing]
âš ï¸ BDD-NN: Acceptance tests not executed
   â†“
Production: â³ Not deployed
```

**Status**: ðŸ”´ Incomplete chain with multiple gaps

### 3.3 Example 3: Interface-Heavy Implementation

```
BRD-NN: External data provider integration
   â†“
PRD-NN: External API integration
   â†“
EARS-NN: WHEN system requests item data, THE system SHALL receive response WITHIN [time]
   â†“
BDD-NN: API integration test scenarios
   â†“
ADR-NN: External API integration architecture
   â†“
REQ-NN: Fetch real-time item data from external provider
   â†“
CTR-NN: External Provider API contract (.md + .yaml)
   â”œâ”€ SPEC-NN: API client specification (consumer)
   â””â”€ SPEC-NN: Data transformation service (processor)
   â†“
TASKS-NN: API client implementation tasks
TASKS-NN: Data transformation tasks
   â†“
Code: src/integrations/external_api/
   â”œâ”€ client.py (implements CTR-NN consumer)
   â”œâ”€ transformer.py (data processing)
   â””â”€ rate_limiter.py (API throttling)
   â†“
Tests:
   â”œâ”€ tests/integration/test_external_api.py
   â”œâ”€ tests/contract/test_ctr_003.py
   â””â”€ tests/unit/test_transformer.py
   â†“
BDD-NN: Integration tests pass (5/5 scenarios)
   â†“
Production: âœ… Deployed v1.1.0
```

**Status**: âœ… Complete with strong contract-based traceability

---

## 4. Coverage Metrics and Gap Analysis

### 4.1 Document Type Coverage

| Document Type | Expected | Created | Gap | Coverage % | Target % | Status |
|---------------|----------|---------|-----|------------|----------|--------|
| BRD | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| PRD | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| EARS | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| BDD | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| ADR | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| SYS | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| REQ | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| CTR | [X] | [Y] | [Z] | XX% | 80% | [Status] |
| SPEC | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| TASKS | [X] | [Y] | [Z] | XX% | 100% | [Status] |
| Code | [X] | [Y] | [Z] | XX% | 100% | [Status] |

### 4.2 Traceability Chain Completeness

| Chain Type | Total Chains | Complete | Partial | Broken | Completeness % |
|------------|--------------|----------|---------|--------|----------------|
| Strategy â†’ BRD â†’ PRD | [X] | [Y] | [Z] | [A] | XX% |
| PRD â†’ EARS â†’ BDD | [X] | [Y] | [Z] | [A] | XX% |
| EARS â†’ ADR â†’ SYS â†’ REQ | [X] | [Y] | [Z] | [A] | XX% |
| REQ â†’ CTR â†’ SPEC â†’ TASKS | [X] | [Y] | [Z] | [A] | XX% |
| SPEC â†’ TASKS â†’ Code â†’ Tests | [X] | [Y] | [Z] | [A] | XX% |
| BDD â†’ Tests â†’ Production | [X] | [Y] | [Z] | [A] | XX% |
| **End-to-End Complete** | **[X]** | **[Y]** | **[Z]** | **[A]** | **XX%** |

### 4.3 Orphaned Documents (No Upstream Traceability)

| Document Type | Orphaned Documents | Impact | Action Required |
|---------------|-------------------|--------|-----------------|
| PRD | [List PRD IDs] | No business justification | Link to BRD or create BRD |
| EARS | [List EARS IDs] | No product context | Link to PRD or validate necessity |
| REQ | [List REQ IDs] | No requirements source | Link to 03_EARS/SYS or deprecate |
| SPEC | [List SPEC IDs] | No requirements basis | Link to REQ or validate purpose |
| Code | [List file paths] | No specification | Create 09_SPEC/TASKS or refactor |

### 4.4 Missing Downstream Artifacts (Incomplete Chains)

| Source Document | Missing Artifact Type | Count | Impact | Priority |
|-----------------|----------------------|-------|--------|----------|
| BRD-XXX | PRD | [X] | Business requirements not translated | High |
| PRD-YYY | EARS | [X] | Features not formalized | High |
| EARS-ZZZ | BDD | [X] | Requirements not testable | Critical |
| REQ-AAA | SPEC | [X] | Requirements not specified | High |
| SPEC-BBB | TASKS | [X] | Specifications not implementable | Medium |
| TASKS-CCC | Code | [X] | Tasks not executed | High |

---

## 5. Complete Dependency Graph

### 5.1 Full Workflow Visualization

```mermaid
graph TD
    Strategy[Strategic Goals] --> BRD1[BRD Documents]
    BRD1 --> PRD1[PRD Documents]
    PRD1 --> EARS1[EARS Documents]

    EARS1 --> BDD1[BDD Test Scenarios]
    EARS1 --> ADR1[ADR Decisions]
    PRD1 --> ADR1

    ADR1 --> SYS1[SYS Requirements]
    EARS1 --> REQ1[REQ Atomic Requirements]
    SYS1 --> REQ1

REQ1 --> CTR1[CTR API Contracts]
REQ1 --> SPEC1
CTR1 --> SPEC1


    SPEC1 --> TASKS1[TASKS Code Plans]
    TASKS1 --> Code1[Code Implementation]
    TASKS1 --> Tests1[Test Suites]

    BDD1 --> Tests1
    Tests1 --> Validation[Validation & Review]
    Validation --> Production[Production Deployment]

    style BRD1 fill:#e1f5ff
    style PRD1 fill:#fff4e1
    style EARS1 fill:#e8f5e9
    style BDD1 fill:#e3f2fd
    style ADR1 fill:#f3e5f5
    style SYS1 fill:#fff3e0
    style REQ1 fill:#e8f5e9
        style CTR1 fill:#fff3e0
    style SPEC1 fill:#e3f2fd
    style TASKS1 fill:#fff3e0
    style Code1 fill:#c8e6c9
    style Tests1 fill:#e3f2fd
    style Production fill:#a5d6a7
```

> **Note on Diagram Labels**: The above flowchart shows the sequential workflow. For formal layer numbers used in cumulative tagging, always reference the 15-layer architecture (Layers 0-14) defined in README.md. Diagram groupings are for visual clarity only.

### 5.2 Document Type Relationships Matrix

| From â†“ / To â†’ | BRD | PRD | EARS | BDD | ADR | SYS | REQ | CTR | SPEC | TASKS | Code |
|---------------|-----|-----|------|-----|-----|-----|-----|-----|------|-------|------|
| **Strategy** | âœ“ | | | | | | | | | | | |
| **BRD** | | âœ“ | âœ“ | | âœ“ | | | | | | | |
| **PRD** | | | âœ“ | âœ“ | âœ“ | | | | | | | |
| **EARS** | | | | âœ“ | âœ“ | âœ“ | âœ“ | | | | | |
| **BDD** | | | | | âœ“ | | | | | | | âœ“ |
| **ADR** | | | | | | âœ“ | âœ“ | âœ“ | | âœ“ | | |
| **SYS** | | | | | | | âœ“ | | | âœ“ | | |
| **REQ** | | | | | | | | âœ“ | âœ“ | | |
| **CTR** | | | | | | | | | âœ“ | | âœ“ |
| **SPEC** | | | | | | | | | | âœ“ | |
| **TASKS** | | | | | | | | | | | âœ“ |

**Legend**: âœ“ = Direct traceability relationship exists

---

## 6. Change Impact Analysis Guidelines

### 6.1 Impact Analysis Process

When making changes to any document, use this matrix to identify affected artifacts:

**Step 1: Identify Changed Document**
- Document Type: [01_BRD/02_PRD/03_EARS/etc.]
- Document ID: [DOC-NN]
- Change Type: [New/Modified/Deprecated]

**Step 2: Analyze Downstream Impact**
```
Changed Document: [DOC-NN]
   â†“
Direct Downstream (Tier 1):
   - [List immediate downstream documents]
   â†“
Indirect Downstream (Tier 2):
   - [List second-level downstream documents]
   â†“
Final Impact (Tier 3+):
   - [List third-level and beyond]
```

**Step 3: Assess Impact Severity**
| Affected Artifact | Impact Type | Severity | Action Required |
|-------------------|-------------|----------|-----------------|
| [DOC-ID] | [Breaking/Non-Breaking/Informational] | [Critical/High/Medium/Low] | [Specific action] |

### 6.2 Change Impact Examples

**Example: Changing BRD-NN (Business Requirement Change)**
```
BRD-NN: service integration Requirements
   â†“ Direct Impact (Tier 1)
   PRD-NN: operation execution Features (Requires review and potential update)
   â†“ Indirect Impact (Tier 2)
   EARS-NN: Formal operation requirements (May need revision)
   BDD-NN: Test scenarios (May need new scenarios)
   ADR-NN: Architecture decision (May need reconsideration)
   â†“ Cascading Impact (Tier 3)
   SYS-NN, REQ-NN: System/atomic requirements (Potential updates)
CTR-NN, SPEC-NN, TASKS-NN: Implementation artifacts (Code changes)

   â†“ Final Impact (Tier 4)
   Code: src/execution/order_service.py (Refactoring required)
   Tests: tests/test_order_service.py (Test updates)
   Production: Requires release planning
```

**Impact Assessment**:
- **Severity**: High (affects production code)
- **Affected Teams**: Business, Product, Architecture, Backend Development
- **Estimated Effort**: 40 developer-hours + testing
- **Release Impact**: Requires hotfix or next release cycle

### 6.3 Impact Analysis Checklist

Before making changes, verify:
- [ ] All downstream documents identified
- [ ] Impact severity assessed for each artifact
- [ ] Affected teams notified
- [ ] Timeline and effort estimated
- [ ] Test impact analyzed
- [ ] Production deployment plan created
- [ ] Rollback plan prepared (if breaking change)
- [ ] Documentation updates planned
- [ ] Stakeholder approval obtained

---

## 7. Validation and Quality Gates

### 7.1 Traceability Validation Checklist

**Document Creation Validation**:
- [ ] All new documents linked to upstream sources
- [ ] Document follows naming conventions (TYPE-NN_slug)
- [ ] section 7 Traceability complete (upstream + downstream)
- [ ] All referenced documents exist
- [ ] All markdown links include anchors
- [ ] Relative paths correct

**Workflow Completeness Validation**:
- [ ] Business requirements (01_BRD/02_PRD/EARS) complete
- [ ] Acceptance criteria (BDD) defined
- [ ] Architecture decisions (ADR) documented
- [ ] Atomic requirements (REQ) specified
- [ ] API contract (CTR) created (if interface required)
- [ ] Technical specifications (SPEC) written
- [ ] Code generation tasks (TASKS) defined
- [ ] Code implementation complete
- [ ] Tests passing (unit + integration + BDD)
- [ ] Production deployment successful

**Quality Gates by Layer**:
- **Business Layer**: 100% BRD â†’ PRD â†’ EARS linkage
- **Testing Layer**: 100% EARS â†’ BDD coverage
- **Architecture Layer**: 100% ADR â†’ SYS â†’ REQ linkage
- **Requirements Layer**: 100% REQ â†’ SPEC linkage
- **Technical Specs (SPEC)**: 100% SPEC â†’ TASKS â†’ Code linkage
- **Validation Layer**: 95%+ test coverage, all BDD scenarios passing

### 7.2 Automated Validation Commands

**Tag-Based Validation (Recommended):**
```bash
# Complete workflow: Extract â†’ Validate â†’ Generate
python scripts/generate_traceability_matrix.py --auto

# Extract all tags from codebase
python scripts/extract_tags.py \
  --source src/ docs/ tests/ \
  --output docs/generated/tags.json

# Validate tags against documents
python scripts/validate_tags_against_docs.py \
  --tags docs/generated/tags.json \
  --strict

# Generate bidirectional traceability matrices
python scripts/generate_traceability_matrix.py \
  --tags docs/generated/tags.json \
  --output docs/generated/matrices/ \
  --report

# Validate only (no file generation)
python scripts/extract_tags.py --validate-only
```

**Legacy Manual Validation (Optional):**
```bash
# Check broken references across all documents
python scripts/validate_links.py \
  --scan-all \
  --fix-relative-paths

# Validate document naming conventions
python 07_REQ/scripts/validate_requirement_ids.py \
  --all-types \
  --check-anchors
```

### 7.3 Continuous Validation

**Pre-Commit Hooks (Tag-Based)**:
- Extract and validate tag format: `python scripts/extract_tags.py --validate-only`
- Validate tags against documents: `python scripts/validate_tags_against_docs.py --strict`
- Verify all tags resolve to real requirements
- Check implementation status values

**CI/CD Pipeline Checks**:
- Run tag-based traceability validation
- Generate coverage reports from tags
- Check for orphaned tags (tags referencing non-existent documents)
- Validate YAML schemas (SPEC, CTR)
- Run BDD acceptance tests
- Auto-generate traceability matrices

**Scheduled Reviews**:
- Weekly: Review partial chains, identify gaps
- Monthly: Full traceability audit, update matrix
- Quarterly: Architecture review, ADR validation
- Annually: Complete workflow assessment

---

## 8. Revision History

| Version | Date | Changes | Author |
|---------|------|---------|--------|
| 1.0.0 | YYYY-MM-DD | Initial complete traceability matrix creation | [Author Name] |
| 0.9.0 | YYYY-MM-DD | Draft version for stakeholder review | [Author Name] |

---

## 9. References

### 9.1 Internal Documentation
- **Individual Matrix Templates**:
  - [BRD Matrix](01_BRD/BRD-00_TRACEABILITY_MATRIX-TEMPLATE.md)
  - [PRD Matrix](02_PRD/PRD-00_TRACEABILITY_MATRIX-TEMPLATE.md)
  - [EARS Matrix](03_EARS/EARS-00_TRACEABILITY_MATRIX-TEMPLATE.md)
  - [BDD Matrix](04_BDD/BDD-00_TRACEABILITY_MATRIX-TEMPLATE.md)
  - [ADR Matrix](05_ADR/ADR-00_TRACEABILITY_MATRIX-TEMPLATE.md)
  - [SYS Matrix](06_SYS/SYS-00_TRACEABILITY_MATRIX-TEMPLATE.md)
  - [REQ Matrix](07_REQ/REQ-00_TRACEABILITY_MATRIX-TEMPLATE.md)
- [CTR Matrix](08_CTR/CTR-00_TRACEABILITY_MATRIX-TEMPLATE.md)
- [SPEC Matrix](09_SPEC/SPEC-00_TRACEABILITY_MATRIX-TEMPLATE.md)
- [TASKS Matrix](11_TASKS/TASKS-00_TRACEABILITY_MATRIX-TEMPLATE.md)


- **Workflow Guides**:
  - [SPEC_DRIVEN_DEVELOPMENT_GUIDE.md](SPEC_DRIVEN_DEVELOPMENT_GUIDE.md)
  - [TRACEABILITY.md](TRACEABILITY.md)
  - [index.md - Traceability Flow](index.md#traceability-flow)

### 9.2 External Standards
- ISO/IEC/IEEE 29148:2018 - Systems and software engineering requirements
- ISO/IEC/IEEE 15288:2023 - Systems engineering life cycle processes
- CMMI for Development - Requirements Development and Management
- Agile Traceability Best Practices

### 9.3 Traceability Tools
- Python validation scripts in `/scripts/` directory
- Automated matrix generation tools
- CI/CD pipeline integration

---

## 10. Appendix A: Matrix Usage Scenarios

### 10.1 Scenario 1: New Feature Development
1. **Start**: Strategic goal identified
2. **Create**: BRD â†’ PRD â†’ EARS â†’ BDD
3. **Design**: ADR â†’ SYS â†’ REQ
4. **Plan**: CTR (if API) â†’ SPEC â†’ TASKS
5. **Implement**: Code â†’ Tests
6. **Validate**: BDD scenarios â†’ Production
7. **Update Matrix**: Track all artifacts created

### 10.2 Scenario 2: Production Issue Investigation
1. **Identify**: Issue in production code
2. **Trace Back**: Code â†’ TASKS â†’ SPEC â†’ REQ â†’ EARS â†’ PRD â†’ BRD
3. **Analyze**: Determine if issue is:
   - Implementation bug (Code/TASKS)
   - Specification error (SPEC)
   - Requirements gap (07_REQ/EARS)
   - Design flaw (05_ADR/SYS)
   - Business misalignment (01_BRD/PRD)
4. **Fix**: Update appropriate layer
5. **Impact Analysis**: Use matrix to identify all affected artifacts
6. **Remediate**: Update downstream artifacts
7. **Validate**: Re-run BDD scenarios

### 10.3 Scenario 3: Requirements Change Request
1. **Change Request**: Update to EARS-NN
2. **Impact Analysis**: Use matrix to find:
   - Upstream: Which 02_PRD/BRD drives this requirement?
   - Downstream: Which BDD, REQ, SPEC, Code affected?
3. **Assess**: Determine change scope and effort
4. **Approve**: Stakeholder sign-off on impact
5. **Execute**: Update EARS-NN + all downstream artifacts
6. **Validate**: Run affected BDD scenarios
7. **Update Matrix**: Reflect changes

### 10.4 Scenario 4: Architecture Decision Update
1. **New ADR**: ADR (TBD) supersedes ADR (previous)
2. **Find Affected**:
   - Upstream: Which 01_BRD/02_PRD/EARS drove ADR (previous)?
   - Downstream: Which SYS, REQ, SPEC, Code implement ADR (previous)?
3. **Plan Migration**:
   - Create CTR for interface changes (if needed)
   - Update all affected SPEC
   - Generate new TASKS
   - Schedule code refactoring
4. **Execute**: Systematic update of all layers
5. **Validate**: Full regression testing
6. **Update Matrix**: Track superseded ADR

---

## 11. Appendix B: Metrics Dashboard

### 11.1 Overall Health Score

```
Traceability Health Score: [XX]/100

Components:
- Document Coverage: [XX%] (weight: 30%)
- Chain Completeness: [XX%] (weight: 25%)
- Orphaned Documents: [XX%] (weight: 15%)
- Broken Links: [XX%] (weight: 10%)
- Test Coverage: [XX%] (weight: 10%)
- Production Deployment: [XX%] (weight: 10%)
```

### 11.2 Key Performance Indicators

**Tag-Based Metrics (Auto-Calculated):**
```bash
python scripts/generate_traceability_matrix.py --auto --report
```

| KPI | Current | Target | Status |
|-----|---------|--------|--------|
| End-to-End Chain Completeness | XX% | 95% | [Status] |
| Tag Coverage (Code Files with Tags) | XX% | 90% | [Status] |
| Tag Format Compliance | XX% | 100% | [Status] |
| Requirements with Code Tags | XX% | 85% | [Status] |
| Orphaned Tags (Invalid References) | [X] | 0 | [Status] |
| Implementation Status Tracking | XX% | 100% | [Status] |
| Upstream Traceability Coverage | XX% | 100% | [Status] |
| Downstream Artifact Coverage | XX% | 95% | [Status] |
| BDD Scenario Pass Rate | XX% | 95% | [Status] |
| Test Coverage (Code) | XX% | 85% | [Status] |
| Production Deployment Success | XX% | 100% | [Status] |

---

**Matrix Status**: âœ… Active and Maintained
**Last Full Validation**: YYYY-MM-DD
**Next Scheduled Update**: YYYY-MM-DD
