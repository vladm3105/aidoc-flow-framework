# FTEST-MVP-TEMPLATE.yaml
# Functional Test Specification Template for Autopilot Workflow
# Schema: FTEST_MVP_SCHEMA.yaml

metadata:
  document_id: "FTEST-NN"
  title: "[System Scope] Functional Test Specification"
  artifact_type: "FTEST"
  layer: 10
  test_type_code: 43
  template_profile: "mvp"
  schema_version: "1.0"

document_control:
  status: "Draft"
  version: "0.1.0"
  date_created: "YYYY-MM-DD"
  last_updated: "YYYY-MM-DD"
  author: "[Author name]"
  system_scope: "[System/component name]"
  sys_reference: "SYS.NN.01.01"
  quality_attributes:
    - "Performance"
    - "Reliability"
    - "Security"
  coverage_target: 85
  tasks_ready_score: null
  template_version: "1.0"

test_scope:
  system_under_test:
    system: "[System name]"
    version: "[Version]"
    environment: "[Test environment]"
    sys_reference: "SYS.NN.01.01"

  quality_attributes:
    - attribute: "Performance"
      sys_reference: "SYS.NN.01.01"
      threshold_reference: "TH-PERF-001"
    - attribute: "Reliability"
      sys_reference: "SYS.NN.02.01"
      threshold_reference: "TH-REL-001"
    - attribute: "Security"
      sys_reference: "SYS.NN.03.01"
      threshold_reference: "TH-SEC-001"

  threshold_definitions:
    - id: "TH-PERF-001"
      attribute: "Response Time"
      metric: "P95 latency"
      target: "<200ms"
      source: "SYS.NN.01.01"
    - id: "TH-REL-001"
      attribute: "Availability"
      metric: "Uptime"
      target: "99.9%"
      source: "SYS.NN.02.01"

test_case_index:
  - id: "TSPEC.NN.43.01"
    name: "Response Time"
    quality_attribute: "Performance"
    sys_coverage: "SYS.NN.01.01"
    priority: "P1"
  - id: "TSPEC.NN.43.02"
    name: "System Availability"
    quality_attribute: "Reliability"
    sys_coverage: "SYS.NN.02.01"
    priority: "P1"

test_case_details:
  - id: "TSPEC.NN.43.01"
    name: "Response Time Performance Test"
    quality_attribute: "Performance"
    traceability:
      sys: "SYS.NN.01.01"
      threshold: "TH-PERF-001"
      threshold_value: "<200ms P95"
      spec: "SPEC-NN"
    threshold_validation:
      - metric: "P50 latency"
        threshold: "<100ms"
        measurement: "Percentile calculation"
      - metric: "P95 latency"
        threshold: "<200ms"
        measurement: "Percentile calculation"
    workflow_steps:
      - step: 1
        action: "Generate baseline load"
        expected_result: "System stable"
      - step: 2
        action: "Execute 1000 requests"
        expected_result: "Responses captured"
      - step: 3
        action: "Calculate percentiles"
        expected_result: "P50, P95, P99"
      - step: 4
        action: "Compare to thresholds"
        expected_result: "All pass"
    measurement_methodology: |
      latencies = []
      for _ in range(1000):
          start = time.time()
          response = client.get("/api/endpoint")
          latencies.append((time.time() - start) * 1000)
      p95 = statistics.quantiles(latencies, n=20)[18]
      assert p95 < 200

sys_coverage_matrix:
  - sys_id: "SYS.NN.01.01"
    quality_attribute: "Performance"
    test_ids:
      - "TSPEC.NN.43.01"
    covered: true
  - sys_id: "SYS.NN.02.01"
    quality_attribute: "Reliability"
    test_ids:
      - "TSPEC.NN.43.02"
    covered: true

coverage_summary:
  total_sys_attributes: 0
  covered: 0
  coverage_percent: 0

traceability:
  upstream:
    - tag: "@sys"
      reference: "SYS.NN.01.01"
      description: "System requirement"
    - tag: "@threshold"
      reference: "TH-PERF-001"
      description: "Performance threshold"
    - tag: "@spec"
      reference: "SPEC-NN"
      description: "Technical specification"
  downstream:
    - tag: "@tasks"
      reference: "TASKS-NN"
      description: "Implementation tasks"
    - tag: "@code"
      reference: "tests/functional/test_[scope].py"
      description: "Test implementation"
