---
title: "MVP Automation Design"
tags:
  - framework-guide
  - mvp-workflow
  - ai-agent-primary
custom_fields:
  document_type: design
  priority: primary
  development_status: active
---

# MVP Automation Strategy: "The MVP Autopilot"

**Framework Philosophy**: Maximum velocity to production through 90%+ automation with strategic human oversight.

## Goal
Create a unified automation tool (`mvp_autopilot.py`) that executes the **6-Step MVP Workflow** sequentially from BRD to TASKS with a single command, enabling rapid 1-2 week cycles from business idea to production MVP.

**Automation Capabilities**:
- Single-command scaffolding of all MVP artifacts (BRD → TASKS)
- Quality-gated progression with auto-approve when score ≥90%
- Auto-fix strategies to maintain velocity
- Complete traceability chain automation
- Supports continuous delivery loop: MVP v1.0 → Defects → Production → MVP v2.0

## Core Philosophy
The automation treats the `ai_dev_flow` framework as a **compile target**. It moves through layers (BRD -> PRD -> EARS -> ...) only when the previous layer passes validation gates, enabling rapid iteration while preserving quality.

## Architecture

### 1. The Controller (`AUTOPILOT/scripts/mvp_autopilot.py`)
A Python script that manages the state machine.

**Inputs:**
- `--project-root`: Path to project docs.
- `--intent`: High-level description (seed for BRD).
- `--model`: LLM to use for generation (via API/CLI).

**The Loop (Per Layer):**
1.  **Context Assembly**: Read previous layers + `MVP-TEMPLATE` + `CREATION_RULES`.
2.  **Planning Check**: Verify `_required_documents_list.md` exists.
3.  **Generation**:
    - If file missing: Call LLM to generate.
    - If file exists: Skip or Refine.
4.  **Validation**: Run specific `validate_X.py`.
5.  **Self-Correction (The "Fix" Loop)**:
    - If validation fails: Capture `stderr`.
    - Feed `Document Content` + `Validation Errors` back to LLM.
    - Prompt: "Fix the following validation errors in the markdown..."
    - Overwrite file.
    - Retry Validation (Max 3 attempts).
6.  **Corpus Gate**: Run `validate_links.py`. Any failure halts progress.

### 2. Integration with LLM
The script needs an `LLMProvider` interface.
- **Option A (CLI)**: Pipe to standard CLI tools like `llm` or `openai-cli`.
- **Option B (API)**: Direct Python calls (OpenAI/Anthropic/Gemini).
- **Option C (Agent)**: The script generates a "Prompt File" for an Agent to consume.

*Recommendation*: **Option B** (Python `litellm` or similar) for tight loop control.

## Proposed Workflow Execution

```bash
# Example Usage
python3 AUTOPILOT/scripts/mvp_autopilot.py \
  --root /opt/data/my_project \
  --intent "A trading bot for crypto using moving averages" \
  --auto-fix
```

### Layer Execution Order
1.  **BRD**: generated from `--intent`.
2.  **PRD**: generated from `BRD`.
3.  **EARS**: generated from `PRD`.
4.  **BDD**: generated from `EARS`.
5.  **Index/Lists**: Auto-generated by the script based on templates.

## Implementation Steps

1.  **Project Initializer**:
    - Creates `docs/BRD`, `docs/PRD`, etc.
    - Copies `MVP-TEMPLATES` as reference.

2.  **The `LayerProcessor` Class**:
    - `process_layer("BRD", context_files=[...], validators=[...])`

3.  **The Validator Bridge**:
    - Wraps the existing shell/python scripts.
    - Returns `(success: bool, output: str)`.

4.  **The Healer**:
    - A dedicated prompt strategy for fixing specific validation errors (e.g., "Missing Traceability Tag").

## Next Steps for User
1.  Approve this architecture.
2.  Decide on the LLM backend (API Key or CLI tool).
3.  I can scaffold `mvp_autopilot.py` with the structure but "mock" the LLM generation for you to fill in.
